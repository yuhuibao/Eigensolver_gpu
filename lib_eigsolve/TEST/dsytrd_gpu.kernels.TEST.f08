! This file was generated by gpufort

 
! 
! Hints:
! Device variables in scope:
!       character                                 :: uplo

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       real(8), dimension(1:n), device           :: d

!       real(8), dimension(1:n-1), device         :: e

!       real(8), dimension(1:lwork), device       :: work

!       real(8), dimension(1:lda, 1:n), device    :: a

!       real(8), dimension(1:n-1), device         :: tau

!       real(8), parameter                        :: one = 1.0_8

!       type(dim3)                                :: threads

function test_launch_krnl_2b8e8f_0_auto()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  integer(c_int),intent(IN) :: sharedMem
  type(c_ptr),value,intent(IN) :: stream
  INTEGER(kind=),value :: n
  type(c_ptr),value :: d
  integer(c_int),value,intent(IN) :: d_n1
  integer(c_int),value,intent(IN) :: d_lb1
  type(c_ptr),value :: a
  integer(c_int),value,intent(IN) :: a_n1
  integer(c_int),value,intent(IN) :: a_n2
  integer(c_int),value,intent(IN) :: a_lb1
  integer(c_int),value,intent(IN) :: a_lb2
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_krnl_2b8e8f_0_auto(0,c_null_ptr,sharedMem,stream,n,d,d_n1,d_lb1,a,a_n1,a_n2,a_lb1,a_lb2) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_krnl_2b8e8f_0_cpu(0,c_null_ptr,sharedMem,stream,n,d,d_n1,d_lb1,a,a_n1,a_n2,a_lb1,a_lb2)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! 
! Hints:
! Device variables in scope:
!       character                                  :: uplo

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: blocks, threads

!       integer                                    :: blocks, threads

!       real(8), dimension(1:lda, 1:n), device     :: a

!       real(8), dimension(1:ldw, 1:nb), device    :: w

!       real(8), dimension(n-1), device            :: tau

!       real(8), dimension(n-1), device            :: e

!       real(8), parameter                         :: one = 1.0d0, zero = 0.0d0, half = 0.5d0

!       real(8), parameter                         :: one = 1.0d0, zero = 0.0d0, half = 0.5d0

!       real(8), parameter                         :: one = 1.0d0, zero = 0.0d0, half = 0.5d0

!       type(dim3)                                 :: threads2d, blocks2d

!       type(dim3)                                 :: threads2d, blocks2d

function test_launch_krnl_37a79c_1_auto()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  integer(c_int),intent(IN) :: sharedMem
  type(c_ptr),value,intent(IN) :: stream
  type(c_ptr),value :: w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: iw
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_krnl_37a79c_1_auto(0,c_null_ptr,sharedMem,stream,w,w_n1,w_n2,w_lb1,w_lb2,n,iw) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_krnl_37a79c_1_cpu(0,c_null_ptr,sharedMem,stream,w,w_n1,w_n2,w_lb1,w_lb2,n,iw)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine dsyr2_mv_kernel(N, M, V, ldv, W, ldw, x, W2, ldw2)
!        implicit none
!        integer, value                                      :: N, M, ldv, ldw, ldw2
!        real(8), dimension(1:ldv, 1:M), device, intent(in)  :: V
!        real(8), dimension(1:ldw, 1:M), device, intent(in)  :: W
!        real(8), dimension(1:ldw2, 2), device               :: W2
!        real(8), dimension(1:N), device                     :: x
! 
!        integer                                             :: i, j, istat
!        real(8)                                             :: rv
! 
!        i = (blockIdx%x - 1)*blockDim%x + threadIdx%x
!        j = (blockIdx%y - 1)*blockDim%y + threadIdx%y
! 
!        if (i <= N .and. j <= M) then
! 
!           rv = -W(N, j)*V(i, j) - V(N, j)*W(i, j)
! 
!           ! Update x
!           istat = atomicadd(x(i), rv)
!        endif
! 
!        if (threadIdx%y == 1) then
!           ! Zero out column for zhemv call
!           if (i <= N) W2(i, 1) = 0
!           ! Zero out workspace for intermediate zgemv results
!           if (i <= M) then
!              W2(N + i, 1) = 0
!              W2(N + i, 2) = 0
!           endif
!        endif
! 
!     end subroutine dsyr2_mv_kernel
! 
function test_launch_dsyr2_mv_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  INTEGER(kind=),value :: ldw2
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _w2
  integer(c_int),value,intent(IN) :: w2_n1
  integer(c_int),value,intent(IN) :: w2_n2
  integer(c_int),value,intent(IN) :: w2_lb1
  integer(c_int),value,intent(IN) :: w2_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_dsyr2_mv_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_dsyr2_mv_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine dlarfg_kernel(N, e, x, tau)
!        implicit none
!        integer, value                   :: N
!        real(8), device                  :: tau
!        real(8), device                  :: e
!        real(8), dimension(N), device    :: x
! 
!        integer                          :: tid, i, j, nb, istat, laneID
!        real(8)                          :: rv1, rv2, rv3, scal, scal2, alphar, beta, rsum
!        real(8), shared                  :: xnorm
!        real(8), shared                  :: alpha_s
! 
!        tid = threadIdx%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alpha_s = x(N)
!           xnorm = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        alphar = alpha_s
!        rsum = 0.0_8
! 
!        nb = ceiling(real(N)/blockDim%x) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N - 1) then
!              rv1 = x(i)
!              rv1 = rv1*rv1
!           else
!              rv1 = 0.0_8
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(xnorm, rv1)
!        endif
! 
!        call syncthreads()
! 
!        if (xnorm == 0.0_8) then
!           if (tid == 1) then
!              tau = 0.0_8
!           endif
!        else
!           if (tid == 1) then
!              xnorm = sqrt(xnorm)
!              rv1 = abs(alphar)
! 
!              ! not taking abs of xnorm
!              scal = max(rv1, xnorm)
!              scal2 = min(rv1, xnorm)
! 
!              if (scal2 .eq. 0.0d0) then
!                 beta = -sign(scal, alphar)
!              else
!                 beta = -sign(scal*sqrt(1.0d0 + (scal2/scal)**2), alphar)
!              endif
! 
!              tau = (beta - alphar)/beta
! 
!              e = beta ! store beta in e vector
!              alpha_s = 1.d0/(alphar - beta) !scaling factor for dscal
!           endif
! 
!           call syncthreads()
! 
!           do i = tid, N, blockDim%x
! 
!              if (i <= N - 1) then
!                 x(i) = alpha_s*x(i)
!              elseif (i == N) then
!                 x(i) = 1.0_8
!              endif
! 
!           end do
! 
!        endif
! 
!     end subroutine dlarfg_kernel
! 
function test_launch_dlarfg_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  REAL(kind=8),value :: tau
  REAL(kind=8),value :: e
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_dlarfg_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,e,x,x_n1,x_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_dlarfg_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,e,x,x_n1,x_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine dsyr2_mv_dlarfg_kernel(N, M, V, ldv, W, ldw, x, W2, ldw2, e, tau, finished)
!        implicit none
!        integer, value                                      :: N, M, ldv, ldw, ldw2
!        real(8), dimension(1:ldv, 1:M), device, intent(in)  :: V
!        real(8), dimension(1:ldw, 1:M), device, intent(in)  :: W
!        real(8), dimension(1:ldw2, 2), device               :: W2
!        real(8), dimension(1:N), device                     :: x
!        real(8), device                                     :: tau
!        real(8), device                                     :: e
! 
!        integer                                             :: i, j, tx, ty, tid, nb, laneid, istat, nBlocks
!        integer, device                                     :: finished
!        integer, shared                                     :: nFinished
!        real(8)                                             :: rv
!        real(8)                                             :: rv1, rv2, rv3, scal, scal2, alphar, beta, rsum
!        real(8), shared                                     :: xnorm
!        real(8), shared                                     :: alpha_s
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        nBlocks = gridDim%x*gridDim%y
! 
!        if (i <= N .and. j <= M) then
! 
!           rv = -W(N, j)*V(i, j) - V(N, j)*W(i, j)
! 
!           ! Update x
!           istat = atomicadd(x(i), rv)
!        endif
! 
!        if (ty == 1) then
!           ! Zero out column for dgemv call
!           if (i <= N) W2(i, 1) = 0
!           ! Zero out workspace for intermediate dgemv results
!           if (i <= M) then
!              W2(N + i, 1) = 0
!              W2(N + i, 2) = 0
!           endif
!        endif
! 
!        call threadfence()
! 
!        nFinished = 0
!        call syncthreads()
!        if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)
!        call syncthreads()
! 
!        if (nFinished < nBlocks - 1) return
! 
!        ! Begin dlarfg work with last block
!        if (N == 1) return
! 
!        tid = tx + (ty - 1)*blockDim%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alpha_s = x(N - 1)
!           xnorm = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        alphar = alpha_s
!        rsum = 0.0_8
! 
!        nb = ceiling(real(N - 1)/blockDim%x*blockDim%y) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N - 2) then
!              rv1 = x(i)
!              rv1 = rv1*rv1
!           else
!              rv1 = 0.0_8
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x*blockDim%y
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(xnorm, rv1)
!        endif
! 
!        call syncthreads()
! 
!        if (xnorm == 0.0_8) then
!           if (tid == 1) then
!              tau = 0.0_8
!           endif
!        else
!           if (tid == 1) then
!              xnorm = sqrt(xnorm)
!              rv1 = abs(alphar)
! 
!              ! not taking abs of xnorm
!              scal = max(rv1, xnorm)
!              scal2 = min(rv1, xnorm)
! 
!              if (scal2 .eq. 0.0d0) then
!                 beta = -sign(scal, alphar)
!              else
!                 beta = -sign(scal*sqrt(1.0d0 + (scal2/scal)**2), alphar)
!              endif
! 
!              tau = (beta - alphar)/beta
! 
!              e = beta ! store beta in e vector
!              alpha_s = 1.d0/(alphar - beta) !scaling factor for dscal
!           endif
! 
!           call syncthreads()
! 
!           do i = tid, N - 1, blockDim%x*blockDim%y
! 
!              if (i <= N - 2) then
!                 x(i) = alpha_s*x(i)
!              elseif (i == N - 1) then
!                 x(i) = 1.0_8
!              endif
! 
!           end do
! 
!        endif
! 
!     end subroutine dsyr2_mv_dlarfg_kernel
! 
function test_launch_dsyr2_mv_dlarfg_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  INTEGER(kind=),value :: ldw2
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _w2
  integer(c_int),value,intent(IN) :: w2_n1
  integer(c_int),value,intent(IN) :: w2_n2
  integer(c_int),value,intent(IN) :: w2_lb1
  integer(c_int),value,intent(IN) :: w2_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  REAL(kind=8),value :: tau
  REAL(kind=8),value :: e
  INTEGER(kind=),value :: finished
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_dsyr2_mv_dlarfg_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1,tau,e,finished) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_dsyr2_mv_dlarfg_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1,tau,e,finished)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_dgemv_T(M, N, V, ldv, W, ldw, x, z1, z2)
!        use cudafor
!        implicit none
!        integer, value                                  :: M, N, ldv, ldw
!        real(8), dimension(ldv, M), device, intent(in)  :: V
!        real(8), dimension(ldw, M), device, intent(in)  :: W
!        real(8), dimension(N), device, intent(in)       :: x
!        real(8), dimension(M), device                   :: z1, z2
!        !complex(8), dimension(M), device, intent(in)        :: z1, z2
! 
!        !real(8), dimension(32), shared                     :: r_s
!        !real(8), dimension(32), shared                     :: i_s
! 
!        integer :: i, j, tx, ty, istat
!        real(8) :: rv1, rv2, xr
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%y - 1)*blockDim%y + ty
!        j = (blockIdx%x - 1)*blockDim%x + tx
! 
!        !if (i > 2*M .or. j > N) return
!        if (i > 2*M) return
! 
!        xr = x(j)
! 
!        if (j > N) then
!           rv1 = 0.d0
!        else
!           if (i > M) then
!              rv2 = W(j, i - M)
!           else
!              rv2 = V(j, i)
!           endif
! 
!           rv1 = rv2*xr
!        endif
! 
!        !Partial sum within warps using shuffle
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (tx == 1) then
!           if (i > M) then
!              istat = atomicadd(z2(i - M), rv1)
!           else
!              istat = atomicadd(z1(i), rv1)
!           endif
!        endif
! 
!        return
!     end subroutine stacked_dgemv_T
! 
function test_launch_stacked_dgemv_t()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_dgemv_t(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,x,x_n1,x_lb1,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_dgemv_t_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,x,x_n1,x_lb1,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_dgemv_N(M, N, V, ldv, W, ldw, z1, z2, y)
!        use cudafor
!        implicit none
!        integer, value                                     :: M, N, ldv, ldw
!        real(8), dimension(ldv, N), device, intent(in)     :: V
!        real(8), dimension(ldw, N), device, intent(in)     :: W
!        real(8), dimension(N), device, intent(in)          :: z1, z2
!        real(8), dimension(M), device                      :: y
! 
!        integer :: i, j, tx, ty, istat
!        real(8) :: rv1, rv2, xr
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        if (i > M .or. j > 2*N) return
! 
!        if (j > N) then
!           xr = z2(j - N)
!           rv2 = V(i, j - N)
!        else
!           xr = z1(j)
!           rv2 = W(i, j)
!        endif
! 
!        rv1 = -rv2*xr
! 
!        istat = atomicadd(y(i), rv1)
! 
!        return
! 
!     end subroutine stacked_dgemv_N
! 
function test_launch_stacked_dgemv_n()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_dgemv_n(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_dgemv_n_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine finish_W_col_kernel(N, tau, x, y)
!        implicit none
!        integer, value                               :: N
!        real(8), device                              :: tau
!        real(8), dimension(N), device, intent(in)    :: x
!        real(8), dimension(N), device                :: y
! 
!        integer                                      :: tid, i, j, k, nb, istat, laneID
!        real(8)                                      :: rv1, rv2, rsum, mytau
! 
!        real(8), shared                              :: alphar
!        !real(8), shared                              :: alpha
!        real(8)                                      :: alpha
! 
!        tid = threadIdx%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alphar = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        rsum = 0.0_8
!        mytau = tau
! 
!        nb = ceiling(real(N)/blockDim%x) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N) then
!              rv1 = mytau*y(i)*x(i)
!           else
!              rv1 = 0.0d0
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x
! 
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(alphar, rv1)
!        endif
! 
!        call syncthreads()
! 
!        alpha = -0.5d0*mytau*alphar
! 
!        do i = tid, N, blockDim%x
!           y(i) = mytau*y(i) + alpha*x(i) !daxpy
!        end do
! 
!     end subroutine finish_W_col_kernel
! 
function test_launch_finish_w_col_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  REAL(kind=8),value :: tau
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_finish_w_col_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,x,x_n1,x_lb1,y,y_n1,y_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_finish_w_col_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,x,x_n1,x_lb1,y,y_n1,y_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_dgemv_N_finish_W(M, N, V, ldv, W, ldw, z1, z2, y, tau, x, finished)
!        use cudafor
!        implicit none
!        integer, value                                     :: M, N, ldv, ldw
!        real(8), dimension(ldv, N), device, intent(in)     :: V
!        real(8), dimension(ldw, N), device, intent(in)     :: W
!        real(8), dimension(N), device, intent(in)          :: z1, z2
!        real(8), dimension(M), device                      :: y
!        real(8), device                                    :: tau
!        real(8), dimension(M), device, intent(in)          :: x
!        integer, device                                    :: finished
! 
!        integer :: i, j, tx, ty, istat, nBlocks, tid, laneID, nb
!        integer, shared :: nFinished
!        real(8) :: rv1, rv2, rsum, xr, mytau
!        real(8), shared                              :: alphar
!        !real(8), shared                              :: alpha
!        real(8)                                      :: alpha
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        nBlocks = gridDim%x*gridDim%y
! 
!        if (i <= M .and. j <= 2*N) then
! 
!           if (j > N) then
!              xr = z2(j - N)
!              rv2 = V(i, j - N)
!           else
!              xr = z1(j)
!              rv2 = W(i, j)
!           endif
! 
!           rv1 = -rv2*xr
! 
!           istat = atomicadd(y(i), rv1)
!        endif
! 
!        call threadfence()
! 
!        nFinished = 0
!        call syncthreads()
!        if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)
!        call syncthreads()
! 
!        if (nFinished < nBlocks - 1) return
! 
!        ! Begin finish_W_col work with last block
!        tid = threadIdx%x + (threadIdx%y - 1)*blockDim%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alphar = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        rsum = 0.0_8
!        mytau = tau
! 
!        nb = ceiling(real(M)/(blockDim%x*blockDim%y)) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= M) then
!              rv1 = mytau*y(i)*x(i)
!           else
!              rv1 = 0.0d0
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x*blockDim%y
! 
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(alphar, rv1)
!        endif
! 
!        call syncthreads()
! 
!        alpha = -0.5d0*mytau*alphar
! 
!        do i = tid, M, blockDim%x*blockDim%y
!           y(i) = mytau*y(i) + alpha*x(i) !daxpy
!        end do
! 
!     end subroutine stacked_dgemv_N_finish_W
! 
function test_launch_stacked_dgemv_n_finish_w()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use dsytrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  REAL(kind=8),value :: tau
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  INTEGER(kind=),value :: finished
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_dgemv_n_finish_w(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1,tau,x,x_n1,x_lb1,finished) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_dgemv_n_finish_w_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1,tau,x,x_n1,x_lb1,finished)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function


program test_dsytrd_gpu_kernels
  implicit none
  integer :: globalErrorCode = 0, errorCode, fails = 0, tests = 0
  ! declare test functions and return type
  integer :: test_launch_krnl_2b8e8f_0_auto
  integer :: test_launch_krnl_37a79c_1_auto
  integer :: test_launch_dsyr2_mv_kernel
  integer :: test_launch_dlarfg_kernel
  integer :: test_launch_dsyr2_mv_dlarfg_kernel
  integer :: test_launch_stacked_dgemv_t
  integer :: test_launch_stacked_dgemv_n
  integer :: test_launch_finish_w_col_kernel
  integer :: test_launch_stacked_dgemv_n_finish_w
  write(*,*) "SUITE test_dsytrd_gpu_kernels run ..."
  errorCode = test_launch_krnl_2b8e8f_0_auto()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_krnl_2b8e8f_0_auto ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_krnl_2b8e8f_0_auto ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_krnl_37a79c_1_auto()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_krnl_37a79c_1_auto ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_krnl_37a79c_1_auto ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_dsyr2_mv_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_dsyr2_mv_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_dsyr2_mv_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_dlarfg_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_dlarfg_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_dlarfg_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_dsyr2_mv_dlarfg_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_dsyr2_mv_dlarfg_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_dsyr2_mv_dlarfg_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_dgemv_t()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_dgemv_t ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_dgemv_t ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_dgemv_n()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_dgemv_n ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_dgemv_n ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_finish_w_col_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_finish_w_col_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_finish_w_col_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_dgemv_n_finish_w()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_dgemv_n_finish_w ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_dgemv_n_finish_w ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode

  IF (globalErrorCode > 0) THEN
    write(*,*) "SUITE test_dsytrd_gpu_kernels ... FAILURE passed:",(tests-fails)," failed:",fails," total:",tests
  ELSE 
    write(*,*) "SUITE test_dsytrd_gpu_kernels ... SUCCESS passed:",(tests-fails)," failed:",fails," total:",tests
  END IF
end program test_dsytrd_gpu_kernels