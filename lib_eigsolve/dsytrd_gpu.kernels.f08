! This file was generated by gpufort
          
           
module dsytrd_gpu_kernels
  use hip
  implicit none

 
  interface

    subroutine launch_krnl_2b8e8f_0(grid,&
        block,&
        sharedMem,&
        stream,&
        d,&
        a,&
        n) bind(c, name="launch_krnl_2b8e8f_0")
      use iso_c_binding
      use hip
      implicit none
      type(dim3),intent(IN) :: grid
      type(dim3),intent(IN) :: block
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      TODO declaration not found :: d
      TODO declaration not found :: a
      integer,value :: n
    end subroutine

    subroutine launch_krnl_2b8e8f_0_auto(sharedMem,&
        stream,&
        d,&
        a,&
        n) bind(c, name="launch_krnl_2b8e8f_0_auto")
      use iso_c_binding
      use hip
      implicit none
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      TODO declaration not found :: d
      TODO declaration not found :: a
      integer,value :: n
    end subroutine

    subroutine launch_krnl_37a79c_1(grid,&
        block,&
        sharedMem,&
        stream,&
        n,&
        iw,&
        w) bind(c, name="launch_krnl_37a79c_1")
      use iso_c_binding
      use hip
      implicit none
      type(dim3),intent(IN) :: grid
      type(dim3),intent(IN) :: block
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      integer,value :: n
      integer,value :: iw
      TODO declaration not found :: w
    end subroutine

    subroutine launch_krnl_37a79c_1_auto(sharedMem,&
        stream,&
        n,&
        iw,&
        w) bind(c, name="launch_krnl_37a79c_1_auto")
      use iso_c_binding
      use hip
      implicit none
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      integer,value :: n
      integer,value :: iw
      TODO declaration not found :: w
    end subroutine

    subroutine launch_dsyr2_mv_kernel(grid,&
        block,&
        sharedMem,&
        stream,&
        n,&
        m,&
        ldv,&
        ldw,&
        ldw2) bind(c, name="launch_dsyr2_mv_kernel")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: n
      integer,value :: m
      integer,value :: ldv
      integer,value :: ldw
      integer,value :: ldw2
    end subroutine

    subroutine launch_dlarfg_kernel(grid,&
        block,&
        sharedMem,&
        stream,&
        n,&
        tau,&
        e,&
        x) bind(c, name="launch_dlarfg_kernel")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: n
      real(kind=8),value :: tau
      real(kind=8),value :: e
      type(c_ptr),value :: _x
    end subroutine

    subroutine launch_dsyr2_mv_dlarfg_kernel(grid,&
        block,&
        sharedMem,&
        stream,&
        n,&
        m,&
        ldv,&
        ldw,&
        ldw2,&
        tau,&
        e,&
        finished) bind(c, name="launch_dsyr2_mv_dlarfg_kernel")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: n
      integer,value :: m
      integer,value :: ldv
      integer,value :: ldw
      integer,value :: ldw2
      real(kind=8),value :: tau
      real(kind=8),value :: e
      integer,value :: finished
    end subroutine

    subroutine launch_stacked_dgemv_t(grid,&
        block,&
        sharedMem,&
        stream,&
        m,&
        n,&
        ldv,&
        ldw,&
        v,&
        w,&
        x,&
        z1,&
        z2) bind(c, name="launch_stacked_dgemv_t")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _x
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
    end subroutine

    subroutine launch_stacked_dgemv_n(grid,&
        block,&
        sharedMem,&
        stream,&
        m,&
        n,&
        ldv,&
        ldw,&
        v,&
        w,&
        z1,&
        z2,&
        y) bind(c, name="launch_stacked_dgemv_n")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
      type(c_ptr),value :: _y
    end subroutine

    subroutine launch_finish_w_col_kernel(grid,&
        block,&
        sharedMem,&
        stream,&
        n,&
        tau,&
        x,&
        y) bind(c, name="launch_finish_w_col_kernel")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: n
      real(kind=8),value :: tau
      type(c_ptr),value :: _x
      type(c_ptr),value :: _y
    end subroutine

    subroutine launch_stacked_dgemv_n_finish_w(grid,&
        block,&
        sharedMem,&
        stream,&
        m,&
        n,&
        ldv,&
        ldw,&
        v,&
        w,&
        z1,&
        z2,&
        y,&
        tau,&
        x,&
        finished) bind(c, name="launch_stacked_dgemv_n_finish_w")
      use iso_c_binding
      use hip
      implicit none
      type(dim3,,intent(IN, :: grid
      type(dim3,,intent(IN, :: block
      integer(c_int,,intent(IN, :: sharedMem
      type(c_ptr,,value,intent(IN, :: stream
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
      type(c_ptr),value :: _y
      real(kind=8),value :: tau
      type(c_ptr),value :: _x
      integer,value :: finished
    end subroutine

  end interface

  contains

    subroutine launch_krnl_2b8e8f_0_cpu(sharedMem,&
        stream,&
        d,&
        a,&
        n)
      use iso_c_binding
      use hip
      implicit none
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      TODO declaration not found :: d
      TODO declaration not found :: a
      integer,value :: n
      integer :: j
      do j = 33, N
      !A(j-1, j) = e(j-1) ! JR Not strictly needed so skipping this copy
         d(j) = A(j, j)
      end do

    end subroutine

    subroutine launch_krnl_37a79c_1_cpu(sharedMem,&
        stream,&
        n,&
        iw,&
        w)
      use iso_c_binding
      use hip
      implicit none
      integer(c_int),intent(IN) :: sharedMem
      type(c_ptr),value,intent(IN) :: stream
      integer,value :: n
      integer,value :: iw
      TODO declaration not found :: w
      integer :: k
      do k = 1, N - 1
         W(k, iw) = 0.d0
      end do

    end subroutine

    subroutine launch_dsyr2_mv_kernel_cpu(n,&
        m,&
        ldv,&
        ldw,&
        ldw2)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: n
      integer,value :: m
      integer,value :: ldv
      integer,value :: ldw
      integer,value :: ldw2
      integer :: i
      integer :: j
      integer :: istat
      real(kind=8) :: rv
            implicit none

            integer, value                                      :: N, M, ldv, ldw, ldw2

            real(8), dimension(1:ldv, 1:M), device, intent(in)  :: V

            real(8), dimension(1:ldw, 1:M), device, intent(in)  :: W

            real(8), dimension(1:ldw2, 2), device               :: W2

            real(8), dimension(1:N), device                     :: x

            integer                                             :: i, j, istat

            real(8)                                             :: rv

            i = (blockIdx%x - 1)*blockDim%x + threadIdx%x

            j = (blockIdx%y - 1)*blockDim%y + threadIdx%y

            if (i <= N .and. j <= M) then

               rv = -W(N, j)*V(i, j) - V(N, j)*W(i, j)

               ! Update x

               istat = atomicadd(x(i), rv)

            endif

            if (threadIdx%y == 1) then

               ! Zero out column for zhemv call

               if (i <= N) W2(i, 1) = 0

               ! Zero out workspace for intermediate zgemv results

               if (i <= M) then

                  W2(N + i, 1) = 0

                  W2(N + i, 2) = 0

               endif

            endif


    end subroutine

    subroutine launch_dlarfg_kernel_cpu(n,&
        tau,&
        e,&
        _x)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: n
      real(kind=8),value :: tau
      real(kind=8),value :: e
      type(c_ptr),value :: _x
            real(8),target :: x()
      integer :: tid
      integer :: i
      integer :: j
      integer :: nb
      integer :: istat
      integer :: laneid
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: rv3
      real(kind=8) :: scal
      real(kind=8) :: scal2
      real(kind=8) :: alphar
      real(kind=8) :: beta
      real(kind=8) :: rsum
      real(kind=8) :: xnorm
      real(kind=8) :: alpha_s
      CALL hipCheck(hipMemcpy(c_loc(x),_x,C_SIZEOF(x),hipMemcpyDeviceToHost))
            implicit none

            integer, value                   :: N

            real(8), device                  :: tau

            real(8), device                  :: e

            real(8), dimension(N), device    :: x

            integer                          :: tid, i, j, nb, istat, laneID

            real(8)                          :: rv1, rv2, rv3, scal, scal2, alphar, beta, rsum

            real(8), shared                  :: xnorm

            real(8), shared                  :: alpha_s

            tid = threadIdx%x

            laneID = iand(tid, 31)

            if (tid == 1) then

               alpha_s = x(N)

               xnorm = 0.0_8

            endif

            call syncthreads()

            alphar = alpha_s

            rsum = 0.0_8

            nb = ceiling(real(N)/blockDim%x) ! number of blocks down column

            i = tid

            do j = 1, nb

               ! All threads perform their product, zero if out of bounds

               if (i <= N - 1) then

                  rv1 = x(i)

                  rv1 = rv1*rv1

               else

                  rv1 = 0.0_8

               endif

               rsum = rsum + rv1

               i = i + blockDim%x

            end do

            ! Partial sum within warps using shuffle

            rv1 = rsum

            rv2 = __shfl_down(rv1, 1)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 2)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 4)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 8)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 16)

            rv1 = rv1 + rv2

            if (laneID == 1) then

               istat = atomicadd(xnorm, rv1)

            endif

            call syncthreads()

            if (xnorm == 0.0_8) then

               if (tid == 1) then

                  tau = 0.0_8

               endif

            else

               if (tid == 1) then

                  xnorm = sqrt(xnorm)

                  rv1 = abs(alphar)

                  ! not taking abs of xnorm

                  scal = max(rv1, xnorm)

                  scal2 = min(rv1, xnorm)

                  if (scal2 .eq. 0.0d0) then

                     beta = -sign(scal, alphar)

                  else

                     beta = -sign(scal*sqrt(1.0d0 + (scal2/scal)**2), alphar)

                  endif

                  tau = (beta - alphar)/beta

                  e = beta ! store beta in e vector

                  alpha_s = 1.d0/(alphar - beta) !scaling factor for dscal

               endif

               call syncthreads()

               do i = tid, N, blockDim%x

                  if (i <= N - 1) then

                     x(i) = alpha_s*x(i)

                  elseif (i == N) then

                     x(i) = 1.0_8

                  endif

               end do

            endif

      CALL hipCheck(hipMemcpy(_x,c_loc(x),C_SIZEOF(x),hipMemcpyHostToDevice))

    end subroutine

    subroutine launch_dsyr2_mv_dlarfg_kernel_cpu(n,&
        m,&
        ldv,&
        ldw,&
        ldw2,&
        tau,&
        e,&
        finished)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: n
      integer,value :: m
      integer,value :: ldv
      integer,value :: ldw
      integer,value :: ldw2
      real(kind=8),value :: tau
      real(kind=8),value :: e
      integer,value :: finished
      integer :: i
      integer :: j
      integer :: tx
      integer :: ty
      integer :: tid
      integer :: nb
      integer :: laneid
      integer :: istat
      integer :: nblocks
      integer :: nfinished
      real(kind=8) :: rv
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: rv3
      real(kind=8) :: scal
      real(kind=8) :: scal2
      real(kind=8) :: alphar
      real(kind=8) :: beta
      real(kind=8) :: rsum
      real(kind=8) :: xnorm
      real(kind=8) :: alpha_s
            implicit none

            integer, value                                      :: N, M, ldv, ldw, ldw2

            real(8), dimension(1:ldv, 1:M), device, intent(in)  :: V

            real(8), dimension(1:ldw, 1:M), device, intent(in)  :: W

            real(8), dimension(1:ldw2, 2), device               :: W2

            real(8), dimension(1:N), device                     :: x

            real(8), device                                     :: tau

            real(8), device                                     :: e

            integer                                             :: i, j, tx, ty, tid, nb, laneid, istat, nBlocks

            integer, device                                     :: finished

            integer, shared                                     :: nFinished

            real(8)                                             :: rv

            real(8)                                             :: rv1, rv2, rv3, scal, scal2, alphar, beta, rsum

            real(8), shared                                     :: xnorm

            real(8), shared                                     :: alpha_s

            tx = threadIdx%x

            ty = threadIdx%y

            i = (blockIdx%x - 1)*blockDim%x + tx

            j = (blockIdx%y - 1)*blockDim%y + ty

            nBlocks = gridDim%x*gridDim%y

            if (i <= N .and. j <= M) then

               rv = -W(N, j)*V(i, j) - V(N, j)*W(i, j)

               ! Update x

               istat = atomicadd(x(i), rv)

            endif

            if (ty == 1) then

               ! Zero out column for dgemv call

               if (i <= N) W2(i, 1) = 0

               ! Zero out workspace for intermediate dgemv results

               if (i <= M) then

                  W2(N + i, 1) = 0

                  W2(N + i, 2) = 0

               endif

            endif

            call threadfence()

            nFinished = 0

            call syncthreads()

            if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)

            call syncthreads()

            if (nFinished < nBlocks - 1) return

            ! Begin dlarfg work with last block

            if (N == 1) return

            tid = tx + (ty - 1)*blockDim%x

            laneID = iand(tid, 31)

            if (tid == 1) then

               alpha_s = x(N - 1)

               xnorm = 0.0_8

            endif

            call syncthreads()

            alphar = alpha_s

            rsum = 0.0_8

            nb = ceiling(real(N - 1)/blockDim%x*blockDim%y) ! number of blocks down column

            i = tid

            do j = 1, nb

               ! All threads perform their product, zero if out of bounds

               if (i <= N - 2) then

                  rv1 = x(i)

                  rv1 = rv1*rv1

               else

                  rv1 = 0.0_8

               endif

               rsum = rsum + rv1

               i = i + blockDim%x*blockDim%y

            end do

            ! Partial sum within warps using shuffle

            rv1 = rsum

            rv2 = __shfl_down(rv1, 1)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 2)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 4)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 8)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 16)

            rv1 = rv1 + rv2

            if (laneID == 1) then

               istat = atomicadd(xnorm, rv1)

            endif

            call syncthreads()

            if (xnorm == 0.0_8) then

               if (tid == 1) then

                  tau = 0.0_8

               endif

            else

               if (tid == 1) then

                  xnorm = sqrt(xnorm)

                  rv1 = abs(alphar)

                  ! not taking abs of xnorm

                  scal = max(rv1, xnorm)

                  scal2 = min(rv1, xnorm)

                  if (scal2 .eq. 0.0d0) then

                     beta = -sign(scal, alphar)

                  else

                     beta = -sign(scal*sqrt(1.0d0 + (scal2/scal)**2), alphar)

                  endif

                  tau = (beta - alphar)/beta

                  e = beta ! store beta in e vector

                  alpha_s = 1.d0/(alphar - beta) !scaling factor for dscal

               endif

               call syncthreads()

               do i = tid, N - 1, blockDim%x*blockDim%y

                  if (i <= N - 2) then

                     x(i) = alpha_s*x(i)

                  elseif (i == N - 1) then

                     x(i) = 1.0_8

                  endif

               end do

            endif


    end subroutine

    subroutine launch_stacked_dgemv_t_cpu(m,&
        n,&
        ldv,&
        ldw,&
        _v,&
        _w,&
        _x,&
        _z1,&
        _z2)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _x
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
            real(8), M), intent(in)  ,target :: v()
            real(8), M), intent(in)  ,target :: w()
            real(8), intent(in)       ,target :: x()
            real(8),target :: z1()
            real(8),target :: z2()
      integer :: i
      integer :: j
      integer :: tx
      integer :: ty
      integer :: istat
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: xr
      CALL hipCheck(hipMemcpy(c_loc(v),_v,C_SIZEOF(v),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(w),_w,C_SIZEOF(w),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(x),_x,C_SIZEOF(x),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z1),_z1,C_SIZEOF(z1),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z2),_z2,C_SIZEOF(z2),hipMemcpyDeviceToHost))
            use cudafor

            implicit none

            integer, value                                  :: M, N, ldv, ldw

            real(8), dimension(ldv, M), device, intent(in)  :: V

            real(8), dimension(ldw, M), device, intent(in)  :: W

            real(8), dimension(N), device, intent(in)       :: x

            real(8), dimension(M), device                   :: z1, z2

            !complex(8), dimension(M), device, intent(in)        :: z1, z2

            !real(8), dimension(32), shared                     :: r_s

            !real(8), dimension(32), shared                     :: i_s

            integer :: i, j, tx, ty, istat

            real(8) :: rv1, rv2, xr

            tx = threadIdx%x

            ty = threadIdx%y

            i = (blockIdx%y - 1)*blockDim%y + ty

            j = (blockIdx%x - 1)*blockDim%x + tx

            !if (i > 2*M .or. j > N) return

            if (i > 2*M) return

            xr = x(j)

            if (j > N) then

               rv1 = 0.d0

            else

               if (i > M) then

                  rv2 = W(j, i - M)

               else

                  rv2 = V(j, i)

               endif

               rv1 = rv2*xr

            endif

            !Partial sum within warps using shuffle

            rv2 = __shfl_down(rv1, 1)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 2)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 4)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 8)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 16)

            rv1 = rv1 + rv2

            if (tx == 1) then

               if (i > M) then

                  istat = atomicadd(z2(i - M), rv1)

               else

                  istat = atomicadd(z1(i), rv1)

               endif

            endif

            return
      CALL hipCheck(hipMemcpy(_v,c_loc(v),C_SIZEOF(v),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_w,c_loc(w),C_SIZEOF(w),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_x,c_loc(x),C_SIZEOF(x),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z1,c_loc(z1),C_SIZEOF(z1),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z2,c_loc(z2),C_SIZEOF(z2),hipMemcpyHostToDevice))

    end subroutine

    subroutine launch_stacked_dgemv_n_cpu(m,&
        n,&
        ldv,&
        ldw,&
        _v,&
        _w,&
        _z1,&
        _z2,&
        _y)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
      type(c_ptr),value :: _y
            real(8), N), intent(in)     ,target :: v()
            real(8), N), intent(in)     ,target :: w()
            real(8), intent(in)          ,target :: z1()
            real(8), intent(in)          ,target :: z2()
            real(8),target :: y()
      integer :: i
      integer :: j
      integer :: tx
      integer :: ty
      integer :: istat
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: xr
      CALL hipCheck(hipMemcpy(c_loc(v),_v,C_SIZEOF(v),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(w),_w,C_SIZEOF(w),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z1),_z1,C_SIZEOF(z1),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z2),_z2,C_SIZEOF(z2),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(y),_y,C_SIZEOF(y),hipMemcpyDeviceToHost))
            use cudafor

            implicit none

            integer, value                                     :: M, N, ldv, ldw

            real(8), dimension(ldv, N), device, intent(in)     :: V

            real(8), dimension(ldw, N), device, intent(in)     :: W

            real(8), dimension(N), device, intent(in)          :: z1, z2

            real(8), dimension(M), device                      :: y

            integer :: i, j, tx, ty, istat

            real(8) :: rv1, rv2, xr

            tx = threadIdx%x

            ty = threadIdx%y

            i = (blockIdx%x - 1)*blockDim%x + tx

            j = (blockIdx%y - 1)*blockDim%y + ty

            if (i > M .or. j > 2*N) return

            if (j > N) then

               xr = z2(j - N)

               rv2 = V(i, j - N)

            else

               xr = z1(j)

               rv2 = W(i, j)

            endif

            rv1 = -rv2*xr

            istat = atomicadd(y(i), rv1)

            return

      CALL hipCheck(hipMemcpy(_v,c_loc(v),C_SIZEOF(v),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_w,c_loc(w),C_SIZEOF(w),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z1,c_loc(z1),C_SIZEOF(z1),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z2,c_loc(z2),C_SIZEOF(z2),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_y,c_loc(y),C_SIZEOF(y),hipMemcpyHostToDevice))

    end subroutine

    subroutine launch_finish_w_col_kernel_cpu(n,&
        tau,&
        _x,&
        _y)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: n
      real(kind=8),value :: tau
      type(c_ptr),value :: _x
      type(c_ptr),value :: _y
            real(8), intent(in)    ,target :: x()
            real(8),target :: y()
      integer :: tid
      integer :: i
      integer :: j
      integer :: k
      integer :: nb
      integer :: istat
      integer :: laneid
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: rsum
      real(kind=8) :: mytau
      real(kind=8) :: alphar
      real(kind=8) :: alpha
      CALL hipCheck(hipMemcpy(c_loc(x),_x,C_SIZEOF(x),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(y),_y,C_SIZEOF(y),hipMemcpyDeviceToHost))
            implicit none

            integer, value                               :: N

            real(8), device                              :: tau

            real(8), dimension(N), device, intent(in)    :: x

            real(8), dimension(N), device                :: y

            integer                                      :: tid, i, j, k, nb, istat, laneID

            real(8)                                      :: rv1, rv2, rsum, mytau

            real(8), shared                              :: alphar

            !real(8), shared                              :: alpha

            real(8)                                      :: alpha

            tid = threadIdx%x

            laneID = iand(tid, 31)

            if (tid == 1) then

               alphar = 0.0_8

            endif

            call syncthreads()

            rsum = 0.0_8

            mytau = tau

            nb = ceiling(real(N)/blockDim%x) ! number of blocks down column

            i = tid

            do j = 1, nb

               ! All threads perform their product, zero if out of bounds

               if (i <= N) then

                  rv1 = mytau*y(i)*x(i)

               else

                  rv1 = 0.0d0

               endif

               rsum = rsum + rv1

               i = i + blockDim%x

            end do

            ! Partial sum within warps using shuffle

            rv1 = rsum

            rv2 = __shfl_down(rv1, 1)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 2)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 4)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 8)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 16)

            rv1 = rv1 + rv2

            if (laneID == 1) then

               istat = atomicadd(alphar, rv1)

            endif

            call syncthreads()

            alpha = -0.5d0*mytau*alphar

            do i = tid, N, blockDim%x

               y(i) = mytau*y(i) + alpha*x(i) !daxpy

            end do

      CALL hipCheck(hipMemcpy(_x,c_loc(x),C_SIZEOF(x),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_y,c_loc(y),C_SIZEOF(y),hipMemcpyHostToDevice))

    end subroutine

    subroutine launch_stacked_dgemv_n_finish_w_cpu(m,&
        n,&
        ldv,&
        ldw,&
        _v,&
        _w,&
        _z1,&
        _z2,&
        _y,&
        tau,&
        _x,&
        finished)
      use iso_c_binding
      use hip
      implicit none
      integer,value :: m
      integer,value :: n
      integer,value :: ldv
      integer,value :: ldw
      type(c_ptr),value :: _v
      type(c_ptr),value :: _w
      type(c_ptr),value :: _z1
      type(c_ptr),value :: _z2
      type(c_ptr),value :: _y
      real(kind=8),value :: tau
      type(c_ptr),value :: _x
      integer,value :: finished
            real(8), N), intent(in)     ,target :: v()
            real(8), N), intent(in)     ,target :: w()
            real(8), intent(in)          ,target :: z1()
            real(8), intent(in)          ,target :: z2()
            real(8),target :: y()
            real(8), intent(in)          ,target :: x()
      integer :: i
      integer :: j
      integer :: tx
      integer :: ty
      integer :: istat
      integer :: nblocks
      integer :: tid
      integer :: laneid
      integer :: nb
      integer :: nfinished
      real(kind=8) :: rv1
      real(kind=8) :: rv2
      real(kind=8) :: rsum
      real(kind=8) :: xr
      real(kind=8) :: mytau
      real(kind=8) :: alphar
      real(kind=8) :: alpha
      CALL hipCheck(hipMemcpy(c_loc(v),_v,C_SIZEOF(v),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(w),_w,C_SIZEOF(w),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z1),_z1,C_SIZEOF(z1),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(z2),_z2,C_SIZEOF(z2),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(y),_y,C_SIZEOF(y),hipMemcpyDeviceToHost))
      CALL hipCheck(hipMemcpy(c_loc(x),_x,C_SIZEOF(x),hipMemcpyDeviceToHost))
            use cudafor

            implicit none

            integer, value                                     :: M, N, ldv, ldw

            real(8), dimension(ldv, N), device, intent(in)     :: V

            real(8), dimension(ldw, N), device, intent(in)     :: W

            real(8), dimension(N), device, intent(in)          :: z1, z2

            real(8), dimension(M), device                      :: y

            real(8), device                                    :: tau

            real(8), dimension(M), device, intent(in)          :: x

            integer, device                                    :: finished

            integer :: i, j, tx, ty, istat, nBlocks, tid, laneID, nb

            integer, shared :: nFinished

            real(8) :: rv1, rv2, rsum, xr, mytau

            real(8), shared                              :: alphar

            !real(8), shared                              :: alpha

            real(8)                                      :: alpha

            tx = threadIdx%x

            ty = threadIdx%y

            i = (blockIdx%x - 1)*blockDim%x + tx

            j = (blockIdx%y - 1)*blockDim%y + ty

            nBlocks = gridDim%x*gridDim%y

            if (i <= M .and. j <= 2*N) then

               if (j > N) then

                  xr = z2(j - N)

                  rv2 = V(i, j - N)

               else

                  xr = z1(j)

                  rv2 = W(i, j)

               endif

               rv1 = -rv2*xr

               istat = atomicadd(y(i), rv1)

            endif

            call threadfence()

            nFinished = 0

            call syncthreads()

            if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)

            call syncthreads()

            if (nFinished < nBlocks - 1) return

            ! Begin finish_W_col work with last block

            tid = threadIdx%x + (threadIdx%y - 1)*blockDim%x

            laneID = iand(tid, 31)

            if (tid == 1) then

               alphar = 0.0_8

            endif

            call syncthreads()

            rsum = 0.0_8

            mytau = tau

            nb = ceiling(real(M)/(blockDim%x*blockDim%y)) ! number of blocks down column

            i = tid

            do j = 1, nb

               ! All threads perform their product, zero if out of bounds

               if (i <= M) then

                  rv1 = mytau*y(i)*x(i)

               else

                  rv1 = 0.0d0

               endif

               rsum = rsum + rv1

               i = i + blockDim%x*blockDim%y

            end do

            ! Partial sum within warps using shuffle

            rv1 = rsum

            rv2 = __shfl_down(rv1, 1)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 2)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 4)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 8)

            rv1 = rv1 + rv2

            rv2 = __shfl_down(rv1, 16)

            rv1 = rv1 + rv2

            if (laneID == 1) then

               istat = atomicadd(alphar, rv1)

            endif

            call syncthreads()

            alpha = -0.5d0*mytau*alphar

            do i = tid, M, blockDim%x*blockDim%y

               y(i) = mytau*y(i) + alpha*x(i) !daxpy

            end do

      CALL hipCheck(hipMemcpy(_v,c_loc(v),C_SIZEOF(v),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_w,c_loc(w),C_SIZEOF(w),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z1,c_loc(z1),C_SIZEOF(z1),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_z2,c_loc(z2),C_SIZEOF(z2),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_y,c_loc(y),C_SIZEOF(y),hipMemcpyHostToDevice))
      CALL hipCheck(hipMemcpy(_x,c_loc(x),C_SIZEOF(x),hipMemcpyHostToDevice))

    end subroutine


end module dsytrd_gpu_kernels