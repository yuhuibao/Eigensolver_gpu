! This file was generated by gpufort

 
! 
! Hints:
! Device variables in scope:
!       character                                 :: uplo

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: n, lda, lwork, nb, nx, ldwork, istat

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       integer                                   :: i, j, k, kk

!       real(8), dimension(1:n), device           :: d

!       real(8), dimension(1:n-1), device         :: e

!       complex(8), dimension(1:lwork), device    :: work

!       complex(8), dimension(1:lda, 1:n), device :: a

!       complex(8), dimension(1:n-1), device      :: tau

!       complex(8), parameter                     :: cone = cmplx(1,0,8)

!       real(8), parameter                        :: one = 1.0_8

!       type(dim3)                                :: threads

function test_launch_krnl_2b8e8f_0_auto()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  integer(c_int),intent(IN) :: sharedMem
  type(c_ptr),value,intent(IN) :: stream
  type(c_ptr),value :: a
  integer(c_int),value,intent(IN) :: a_n1
  integer(c_int),value,intent(IN) :: a_n2
  integer(c_int),value,intent(IN) :: a_lb1
  integer(c_int),value,intent(IN) :: a_lb2
  type(c_ptr),value :: d
  integer(c_int),value,intent(IN) :: d_n1
  integer(c_int),value,intent(IN) :: d_lb1
  INTEGER(kind=),value :: n
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_krnl_2b8e8f_0_auto(0,c_null_ptr,sharedMem,stream,a,a_n1,a_n2,a_lb1,a_lb2,d,d_n1,d_lb1,n) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_krnl_2b8e8f_0_cpu(0,c_null_ptr,sharedMem,stream,a,a_n1,a_n2,a_lb1,a_lb2,d,d_n1,d_lb1,n)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! 
! Hints:
! Device variables in scope:
!       character                                  :: uplo

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: n, nb, lda, ldw, istat

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: i, j, k, iw

!       integer                                    :: blocks, threads

!       integer                                    :: blocks, threads

!       complex(8), dimension(1:lda, 1:n), device  :: a

!       complex(8), dimension(1:ldw, 1:nb), device :: w

!       complex(8), dimension(n-1), device         :: tau

!       real(8), dimension(n-1), device            :: e

!       complex(8), parameter                      :: cone = cmplx(1, 0, 8), czero = cmplx(0, 0, 8), chalf = cmplx(0.5, 0, 8)

!       complex(8), parameter                      :: cone = cmplx(1, 0, 8), czero = cmplx(0, 0, 8), chalf = cmplx(0.5, 0, 8)

!       complex(8), parameter                      :: cone = cmplx(1, 0, 8), czero = cmplx(0, 0, 8), chalf = cmplx(0.5, 0, 8)

!       type(dim3)                                 :: threads2d, blocks2d

!       type(dim3)                                 :: threads2d, blocks2d

function test_launch_krnl_9c27cb_1_auto()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  integer(c_int),intent(IN) :: sharedMem
  type(c_ptr),value,intent(IN) :: stream
  INTEGER(kind=),value :: iw
  type(c_ptr),value :: w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  INTEGER(kind=),value :: n
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_krnl_9c27cb_1_auto(0,c_null_ptr,sharedMem,stream,iw,w,w_n1,w_n2,w_lb1,w_lb2,n) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_krnl_9c27cb_1_cpu(0,c_null_ptr,sharedMem,stream,iw,w,w_n1,w_n2,w_lb1,w_lb2,n)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine zher2_mv_kernel(N, M, V, ldv, W, ldw, x, W2, ldw2)
!        implicit none
!        integer, value                                        :: N, M, ldv, ldw, ldw2
!        complex(8), dimension(1:ldv, 1:M), device, intent(in) :: V
!        complex(8), dimension(1:ldw, 1:M), device, intent(in) :: W
!        complex(8), dimension(1:ldw2, 2), device               :: W2
!        !DIR$ IGNORE_TKR x
!        real(8), dimension(1:2*N), device                     :: x
! 
!        integer                                               :: i, j, istat
!        complex(8)                                            :: val
!        real(8)                                               :: rv, iv
! 
!        i = (blockIdx%x - 1)*blockDim%x + threadIdx%x
!        j = (blockIdx%y - 1)*blockDim%y + threadIdx%y
! 
!        if (i <= N .and. j <= M) then
! 
!           val = -conjg(W(N, j))*V(i, j) - conjg(V(N, j))*W(i, j)
!           rv = dble(val)
!           iv = dimag(val)
! 
!           ! Zero out imaginary part on diagonal
!           if (i == N) then
!              iv = 0.d0
!           endif
! 
!           ! Update x
!           istat = atomicadd(x(2*i - 1), rv)
!           istat = atomicadd(x(2*i), iv)
!        endif
! 
!        if (threadIdx%y == 1) then
!           ! Zero out column for zhemv call
!           if (i <= N) W2(i, 1) = 0
!           ! Zero out workspace for intermediate zgemv results
!           if (i <= M) then
!              W2(N + i, 1) = 0
!              W2(N + i, 2) = 0
!           endif
!        endif
! 
!     end subroutine zher2_mv_kernel
! 
function test_launch_zher2_mv_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  INTEGER(kind=),value :: ldw2
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _w2
  integer(c_int),value,intent(IN) :: w2_n1
  integer(c_int),value,intent(IN) :: w2_n2
  integer(c_int),value,intent(IN) :: w2_lb1
  integer(c_int),value,intent(IN) :: w2_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_zher2_mv_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_zher2_mv_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine zlarfg_kernel(N, e, x, tau)
!        implicit none
!        integer, value                   :: N
!        complex(8), device               :: tau
!        real(8), device                  :: e
!        complex(8), dimension(N), device :: x
! 
!        integer                          :: tid, i, j, nb, istat, laneID
!        real(8)                          :: rv1, rv2, rv3, scal, invscal, alphar, alphai, beta, rsum, isum
!        complex(8)                       :: cv1
!        real(8), shared                  :: xnorm
!        complex(8), shared               :: alpha_s
! 
!        tid = threadIdx%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alpha_s = x(N)
!           xnorm = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        alphar = dble(alpha_s)
!        alphai = dimag(alpha_s)
!        rsum = 0.0_8
! 
!        nb = ceiling(real(N)/blockDim%x) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N - 1) then
!              cv1 = x(i)
!              rv2 = dble(cv1); rv3 = dimag(cv1)
!              rv1 = rv2*rv2 + rv3*rv3
!           else
!              rv1 = 0.0_8
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(xnorm, rv1)
!        endif
! 
!        call syncthreads()
! 
!        if (xnorm == 0.0_8 .and. alphai == 0.0_8) then
!           if (tid == 1) then
!              tau = 0.0_8
!           endif
!        else
!           if (tid == 1) then
!              xnorm = sqrt(xnorm)
! 
!              rv1 = abs(alphar)
!              rv2 = abs(alphai)
!              ! not taking abs of xnorm
!              scal = max(rv1, rv2, xnorm)
!              invscal = 1.d0/scal
! 
!              rv1 = rv1*invscal
!              rv2 = rv2*invscal
!              xnorm = xnorm*invscal
! 
!              beta = -sign(scal*sqrt(rv1*rv1 + rv2*rv2 + xnorm*xnorm), alphar)
! 
!              tau = dcmplx((beta - alphar)/beta, -alphai/beta)
! 
!              !zladiv
!              rv1 = dble(alpha_s - beta)
!              rv2 = dimag(alpha_s - beta)
! 
!              if (abs(rv2) .lt. abs(rv1)) then
!                 xnorm = rv2/rv1
!                 invscal = 1.d0/(rv1 + rv2*xnorm)
!                 alpha_s = dcmplx(invscal, -xnorm*invscal)
!              else
!                 xnorm = rv1/rv2
!                 invscal = 1.d0/(rv2 + rv1*xnorm)
!                 alpha_s = dcmplx(xnorm*invscal, -invscal)
!              endif
! 
!              e = beta ! store beta in e vector
!           endif
! 
!           call syncthreads()
! 
!           do i = tid, N, blockDim%x
!              cv1 = x(i)
! 
!              if (i <= N - 1) then
!                 cv1 = alpha_s*cv1
!              elseif (i == N) then
!                 !x(i) = 1.0_8
!                 cv1 = dcmplx(1.0_8, 0.0_8)
!              endif
! 
!              x(i) = cv1
!           end do
! 
!        endif
! 
!     end subroutine zlarfg_kernel
! 
function test_launch_zlarfg_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  COMPLEX(kind=8),value :: tau
  REAL(kind=8),value :: e
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_zlarfg_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,e,x,x_n1,x_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_zlarfg_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,e,x,x_n1,x_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine zher2_mv_zlarfg_kernel(N, M, V, ldv, W, ldw, x, W2, ldw2, e, tau, x2, finished)
!        implicit none
!        integer, value                                        :: N, M, ldv, ldw, ldw2
!        complex(8), dimension(1:ldv, 1:M), device, intent(in) :: V
!        complex(8), dimension(1:ldw, 1:M), device, intent(in) :: W
!        complex(8), dimension(1:ldw2, 2), device              :: W2
!        !DIR$ IGNORE_TKR x
!        real(8), dimension(1:2*N), device                     :: x
!        complex(8), dimension(1:N), device                    :: x2
!        complex(8), device                                    :: tau
!        real(8), device                                       :: e
! 
!        integer                                               :: i, j, tx, ty, tid, nb, laneid, istat, nBlocks
!        integer, device                                       :: finished
!        integer, shared                                       :: nFinished
!        complex(8)                                            :: val
!        real(8)                                               :: rv, iv
!        real(8)                                               :: rv1, rv2, rv3, scal, invscal, alphar, alphai, beta, rsum, isum
!        complex(8)                                            :: cv1
!        real(8), shared                                       :: xnorm
!        complex(8), shared                                    :: alpha_s
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        nBlocks = gridDim%x*gridDim%y
! 
!        !if (i > N .or. j > M) return
!        if (i <= N .and. j <= M) then
! 
!           val = -conjg(W(N, j))*V(i, j) - conjg(V(N, j))*W(i, j)
!           rv = dble(val)
!           iv = dimag(val)
! 
!           ! Zero out imaginary part on diagonal
!           if (i == N) then
!              iv = 0.d0
!           endif
! 
!           ! Update x
!           istat = atomicadd(x(2*i - 1), rv)
!           istat = atomicadd(x(2*i), iv)
!        endif
! 
!        if (ty == 1) then
!           ! Zero out column for zhemv call
!           if (i <= N) W2(i, 1) = 0
!           ! Zero out workspace for intermediate zgemv results
!           if (i <= M) then
!              W2(N + i, 1) = 0
!              W2(N + i, 2) = 0
!           endif
!        endif
! 
!        call threadfence()
! 
!        nFinished = 0
!        call syncthreads()
!        if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)
!        call syncthreads()
! 
!        if (nFinished < nBlocks - 1) return
! 
!        ! Begin zlarfg work with last block
!        if (N == 1) return
! 
!        tid = tx + (ty - 1)*blockDim%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alpha_s = x2(N - 1)
!           xnorm = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        alphar = dble(alpha_s)
!        alphai = dimag(alpha_s)
!        rsum = 0.0_8
! 
!        nb = ceiling(real(N - 1)/(blockDim%x*blockDim%y)) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N - 2) then
!              cv1 = x2(i)
!              rv2 = dble(cv1); rv3 = dimag(cv1)
!              rv1 = rv2*rv2 + rv3*rv3
!           else
!              rv1 = 0.0_8
!           endif
! 
!           rsum = rsum + rv1
! 
!           i = i + blockDim%x*blockDim%y
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(xnorm, rv1)
!        endif
! 
!        call syncthreads()
! 
!        if (xnorm == 0.0_8 .and. alphai == 0.0_8) then
!           if (tid == 1) then
!              tau = 0.0_8
!           endif
!        else
!           if (tid == 1) then
!              xnorm = sqrt(xnorm)
! 
!              rv1 = abs(alphar)
!              rv2 = abs(alphai)
!              ! not taking abs of xnorm
!              scal = max(rv1, rv2, xnorm)
!              invscal = 1.d0/scal
! 
!              rv1 = rv1*invscal
!              rv2 = rv2*invscal
!              xnorm = xnorm*invscal
! 
!              beta = -sign(scal*sqrt(rv1*rv1 + rv2*rv2 + xnorm*xnorm), alphar)
! 
!              tau = dcmplx((beta - alphar)/beta, -alphai/beta)
! 
!              !zladiv
!              rv1 = dble(alpha_s - beta)
!              rv2 = dimag(alpha_s - beta)
! 
!              if (abs(rv2) .lt. abs(rv1)) then
!                 xnorm = rv2/rv1
!                 invscal = 1.d0/(rv1 + rv2*xnorm)
!                 alpha_s = dcmplx(invscal, -xnorm*invscal)
!              else
!                 xnorm = rv1/rv2
!                 invscal = 1.d0/(rv2 + rv1*xnorm)
!                 alpha_s = dcmplx(xnorm*invscal, -invscal)
!              endif
! 
!              e = beta ! store beta in e vector
!           endif
! 
!           call syncthreads()
! 
!           do i = tid, N - 1, blockDim%x*blockDim%y
!              cv1 = x2(i)
! 
!              if (i <= N - 2) then
!                 cv1 = alpha_s*cv1
!              elseif (i == N - 1) then
!                 !x(i) = 1.0_8
!                 cv1 = dcmplx(1.0_8, 0.0_8)
!              endif
! 
!              x2(i) = cv1
!           end do
! 
!        endif
! 
!     end subroutine zher2_mv_zlarfg_kernel
! 
function test_launch_zher2_mv_zlarfg_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  INTEGER(kind=),value :: ldw2
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _w2
  integer(c_int),value,intent(IN) :: w2_n1
  integer(c_int),value,intent(IN) :: w2_n2
  integer(c_int),value,intent(IN) :: w2_lb1
  integer(c_int),value,intent(IN) :: w2_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _x2
  integer(c_int),value,intent(IN) :: x2_n1
  integer(c_int),value,intent(IN) :: x2_lb1
  COMPLEX(kind=8),value :: tau
  REAL(kind=8),value :: e
  INTEGER(kind=),value :: finished
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_zher2_mv_zlarfg_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1,x2,x2_n1,x2_lb1,tau,e,finished) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_zher2_mv_zlarfg_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,m,ldv,ldw,ldw2,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,w2,w2_n1,w2_n2,w2_lb1,w2_lb2,x,x_n1,x_lb1,x2,x2_n1,x2_lb1,tau,e,finished)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_zgemv_C(M, N, V, ldv, W, ldw, x, z1, z2)
!        use cudafor
!        implicit none
!        integer, value                                     :: M, N, ldv, ldw
!        complex(8), dimension(ldv, M), device, intent(in)  :: V
!        complex(8), dimension(ldw, M), device, intent(in)  :: W
!        complex(8), dimension(N), device, intent(in)       :: x
!        !DIR$ IGNORE_TKR z1, z2
!        real(8), dimension(2*M), device                    :: z1, z2
!        !complex(8), dimension(M), device, intent(in)        :: z1, z2
! 
!        !real(8), dimension(32), shared                     :: r_s
!        !real(8), dimension(32), shared                     :: i_s
! 
!        integer :: i, j, tx, ty, istat
!        complex(8) :: val
!        real(8) :: rv1, rv2, iv1, iv2, xr, xi
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%y - 1)*blockDim%y + ty
!        j = (blockIdx%x - 1)*blockDim%x + tx
! 
!        !if (i > 2*M .or. j > N) return
!        if (i > 2*M) return
! 
!        val = x(j)
!        xr = dble(val); xi = dimag(val)
! 
!        if (j > N) then
!           !val = dcmplx(0,0)
!           rv1 = 0.d0; iv1 = 0.d0
!        else
!           if (i > M) then
!              val = W(j, i - M)
!           else
!              val = V(j, i)
!           endif
! 
!           rv2 = dble(val); iv2 = dimag(val)
! 
!           rv1 = rv2*xr + iv2*xi
!           iv1 = rv2*xi - iv2*xr
!        endif
! 
!        !Partial sum within warps using shuffle
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        !if (tx == 1) then
!        !r_s(ty + k*blockDim%y) = rv1
!        !r_s(ty) = rv1
!        !endif
! 
!        !Partial sum within warps using shuffle
!        iv2 = __shfl_down(iv1, 1)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 2)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 4)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 8)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 16)
!        iv1 = iv1 + iv2
! 
!        !if (tx == 1) then
!        !i_s(ty + k*blockDim%y) = iv1
!        !i_s(ty) = iv1
!        !endif
! 
!        !call syncthreads()
! 
!        !if (ty == 1 .and. i+tx-1 <= 2*M) then
!        !  if (i+tx-1 > M) then
!        !    istat = atomicadd(z2(2*(i+tx-1-M) - 1), r_s(tx))
!        !    istat = atomicadd(z2(2*(i+tx-1-M)), i_s(tx))
!        !  else
!        !    istat = atomicadd(z1(2*(i+tx-1) - 1), r_s(tx))
!        !    istat = atomicadd(z1(2*(i+tx-1)), i_s(tx))
!        !  endif
!        !endif
! 
!        if (tx == 1) then
!           if (i > M) then
!              istat = atomicadd(z2(2*(i - M) - 1), rv1)
!              istat = atomicadd(z2(2*(i - M)), iv1)
!           else
!              istat = atomicadd(z1(2*i - 1), rv1)
!              istat = atomicadd(z1(2*i), iv1)
!           endif
!        endif
! 
!        return
!     end subroutine stacked_zgemv_C
! 
function test_launch_stacked_zgemv_c()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_zgemv_c(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,x,x_n1,x_lb1,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_zgemv_c_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,x,x_n1,x_lb1,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_zgemv_N(M, N, V, ldv, W, ldw, z1, z2, y)
!        use cudafor
!        implicit none
!        integer, value                                     :: M, N, ldv, ldw
!        complex(8), dimension(ldv, N), device, intent(in)  :: V
!        complex(8), dimension(ldw, N), device, intent(in)  :: W
!        complex(8), dimension(N), device, intent(in)       :: z1, z2
!        !DIR$ IGNORE_TKR y
!        real(8), dimension(2*M), device                    :: y
! 
!        integer :: i, j, tx, ty, istat
!        complex(8) :: val1, val2
!        real(8) :: rv1, rv2, iv1, iv2, xr, xi
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        if (i > M .or. j > 2*N) return
! 
!        if (j > N) then
!           val1 = z2(j - N)
!           val2 = V(i, j - N)
!        else
!           val1 = z1(j)
!           val2 = W(i, j)
!        endif
!        xr = dble(val1); xi = dimag(val1)
!        rv2 = dble(val2); iv2 = dimag(val2)
! 
!        rv1 = -rv2*xr + iv2*xi
!        iv1 = -rv2*xi - iv2*xr
! 
!        istat = atomicadd(y(2*i - 1), rv1)
!        istat = atomicadd(y(2*i), iv1)
! 
!        return
! 
!     end subroutine stacked_zgemv_N
! 
function test_launch_stacked_zgemv_n()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_zgemv_n(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_zgemv_n_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine finish_W_col_kernel(N, tau, x, y)
!        implicit none
!        integer, value                               :: N
!        complex(8), device                           :: tau
!        complex(8), dimension(N), device, intent(in) :: x
!        complex(8), dimension(N), device             :: y
! 
!        integer                                      :: tid, i, j, k, nb, istat, laneID
!        real(8)                                      :: rv1, rv2, iv1, iv2, rsum, isum
!        complex(8)                                   :: val, cv1, mytau
! 
!        real(8), shared                              :: alphar, alphai
!        !complex(8), shared                          :: alpha
!        complex(8)                                   :: alpha
! 
!        tid = threadIdx%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alphar = 0.0_8
!           alphai = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        rsum = 0.0_8
!        isum = 0.0_8
!        mytau = tau
! 
!        nb = ceiling(real(N)/blockDim%x) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= N) then
!              val = dconjg(mytau*y(i))*x(i)
!           else
!              val = dcmplx(0., 0.)
!           endif
! 
!           rv1 = dble(val); iv1 = dimag(val)
! 
!           rsum = rsum + rv1
!           isum = isum + iv1
! 
!           i = i + blockDim%x
! 
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        iv1 = isum
!        iv2 = __shfl_down(iv1, 1)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 2)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 4)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 8)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 16)
!        iv1 = iv1 + iv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(alphar, rv1)
!           istat = atomicadd(alphai, iv1)
!        endif
! 
!        call syncthreads()
! 
!        alpha = -dcmplx(0.5, 0.0)*mytau*dcmplx(alphar, alphai)
! 
!        do i = tid, N, blockDim%x
!           y(i) = mytau*y(i) + alpha*x(i) !zaxpy
!        end do
! 
!     end subroutine finish_W_col_kernel
! 
function test_launch_finish_w_col_kernel()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: n
  COMPLEX(kind=8),value :: tau
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_finish_w_col_kernel(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,x,x_n1,x_lb1,y,y_n1,y_lb1) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_finish_w_col_kernel_cpu(0,c_null_ptr,grid,block,sharedMem,stream,n,tau,x,x_n1,x_lb1,y,y_n1,y_lb1)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function

 
! Fortran implementation:
!     attributes(global) subroutine stacked_zgemv_N_finish_W(M, N, V, ldv, W, ldw, z1, z2, y, tau, x, y2, finished)
!        use cudafor
!        implicit none
!        integer, value                                     :: M, N, ldv, ldw
!        complex(8), dimension(ldv, N), device, intent(in)  :: V
!        complex(8), dimension(ldw, N), device, intent(in)  :: W
!        complex(8), dimension(N), device, intent(in)       :: z1, z2
!        !DIR$ IGNORE_TKR y
!        real(8), dimension(2*M), device                    :: y
!        complex(8), device                                 :: tau
!        complex(8), dimension(M), device, intent(in)       :: x
!        complex(8), dimension(M), device                   :: y2
!        integer, device                                    :: finished
! 
!        integer :: i, j, tx, ty, istat, nBlocks, tid, laneID, nb
!        integer, shared :: nFinished
!        complex(8) :: val1, val2, mytau, alpha
!        real(8) :: rv1, rv2, iv1, iv2, xr, xi, rsum, isum
!        real(8), shared :: alphar, alphai
! 
!        tx = threadIdx%x
!        ty = threadIdx%y
! 
!        i = (blockIdx%x - 1)*blockDim%x + tx
!        j = (blockIdx%y - 1)*blockDim%y + ty
! 
!        nBlocks = gridDim%x*gridDim%y
! 
!        if (i <= M .and. j <= 2*N) then
!           if (j > N) then
!              val1 = z2(j - N)
!              val2 = V(i, j - N)
!           else
!              val1 = z1(j)
!              val2 = W(i, j)
!           endif
!           xr = dble(val1); xi = dimag(val1)
!           rv2 = dble(val2); iv2 = dimag(val2)
! 
!           rv1 = -rv2*xr + iv2*xi
!           iv1 = -rv2*xi - iv2*xr
! 
!           istat = atomicadd(y(2*i - 1), rv1)
!           istat = atomicadd(y(2*i), iv1)
!        endif
! 
!        call threadfence()
! 
!        nFinished = 0
!        call syncthreads()
!        if (tx + ty == 2) nFinished = atomicinc(finished, nBlocks - 1)
!        call syncthreads()
! 
!        if (nFinished < nBlocks - 1) return
! 
!        ! Begin finish_W_col work with last block
!        tid = threadIdx%x + (threadIdx%y - 1)*blockDim%x
!        laneID = iand(tid, 31)
! 
!        if (tid == 1) then
!           alphar = 0.0_8
!           alphai = 0.0_8
!        endif
! 
!        call syncthreads()
! 
!        rsum = 0.0_8
!        isum = 0.0_8
!        mytau = tau
! 
!        nb = ceiling(real(M)/(blockDim%x*blockDim%y)) ! number of blocks down column
! 
!        i = tid
!        do j = 1, nb
! 
!           ! All threads perform their product, zero if out of bounds
!           if (i <= M) then
!              val1 = dconjg(mytau*y2(i))*x(i)
!           else
!              val1 = dcmplx(0., 0.)
!           endif
! 
!           rv1 = dble(val1); iv1 = dimag(val1)
! 
!           rsum = rsum + rv1
!           isum = isum + iv1
! 
!           i = i + blockDim%x*blockDim%y
! 
!        end do
! 
!        ! Partial sum within warps using shuffle
!        rv1 = rsum
!        rv2 = __shfl_down(rv1, 1)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 2)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 4)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 8)
!        rv1 = rv1 + rv2
!        rv2 = __shfl_down(rv1, 16)
!        rv1 = rv1 + rv2
! 
!        iv1 = isum
!        iv2 = __shfl_down(iv1, 1)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 2)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 4)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 8)
!        iv1 = iv1 + iv2
!        iv2 = __shfl_down(iv1, 16)
!        iv1 = iv1 + iv2
! 
!        if (laneID == 1) then
!           istat = atomicadd(alphar, rv1)
!           istat = atomicadd(alphai, iv1)
!        endif
! 
!        call syncthreads()
! 
!        alpha = -dcmplx(0.5, 0.0)*mytau*dcmplx(alphar, alphai)
! 
!        do i = tid, M, blockDim%x*blockDim%y
!           y2(i) = mytau*y2(i) + alpha*x(i) !zaxpy
!        end do
! 
!     end subroutine stacked_zgemv_N_finish_W
! 
function test_launch_stacked_zgemv_n_finish_w()
  ! errorCode > 0 implies that the test has failed
  use iso_c_binding
  use hip
  use zhetrd_gpu_kernels
  implicit none
  integer :: errorCode = 1
  ! TODO fix parameters
  ! - Add missing arguments
  ! - Determine size of arrays (typically indicated by 'type(c_ptr)' type)
  ! - Add target where we need a pointer
  type(dim3,,intent(IN, :: grid
  type(dim3,,intent(IN, :: block
  integer(c_int,,intent(IN, :: sharedMem
  type(c_ptr,,value,intent(IN, :: stream
  INTEGER(kind=),value :: m
  INTEGER(kind=),value :: n
  INTEGER(kind=),value :: ldv
  INTEGER(kind=),value :: ldw
  type(c_ptr),value :: _v
  integer(c_int),value,intent(IN) :: v_n1
  integer(c_int),value,intent(IN) :: v_n2
  integer(c_int),value,intent(IN) :: v_lb1
  integer(c_int),value,intent(IN) :: v_lb2
  type(c_ptr),value :: _w
  integer(c_int),value,intent(IN) :: w_n1
  integer(c_int),value,intent(IN) :: w_n2
  integer(c_int),value,intent(IN) :: w_lb1
  integer(c_int),value,intent(IN) :: w_lb2
  type(c_ptr),value :: _z1
  integer(c_int),value,intent(IN) :: z1_n1
  integer(c_int),value,intent(IN) :: z1_lb1
  type(c_ptr),value :: _z2
  integer(c_int),value,intent(IN) :: z2_n1
  integer(c_int),value,intent(IN) :: z2_lb1
  type(c_ptr),value :: _y
  integer(c_int),value,intent(IN) :: y_n1
  integer(c_int),value,intent(IN) :: y_lb1
  COMPLEX(kind=8),value :: tau
  type(c_ptr),value :: _x
  integer(c_int),value,intent(IN) :: x_n1
  integer(c_int),value,intent(IN) :: x_lb1
  type(c_ptr),value :: _y2
  integer(c_int),value,intent(IN) :: y2_n1
  integer(c_int),value,intent(IN) :: y2_lb1
  INTEGER(kind=),value :: finished
  ! TODO Create initial data on host
  ! TODO Copy data to device ! (dest,src,size,direction)
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  CALL hipCheck(hipMemcpy(???,c_loc(???),C_SIZEOF(???),hipMemcpyHostToDevice)) ! 
  ! ... might be more (or less) than two memcopies 
  ! TODO run the test
  CALL launch_stacked_zgemv_n_finish_w(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1,tau,x,x_n1,x_lb1,y2,y2_n1,y2_lb1,finished) ! Modify sharedMem if other than default 0
  CALL hipCheck(hipDeviceSynchronize())
  CALL launch_stacked_zgemv_n_finish_w_cpu(0,c_null_ptr,grid,block,sharedMem,stream,m,n,ldv,ldw,v,v_n1,v_n2,v_lb1,v_lb2,w,w_n1,w_n2,w_lb1,w_lb2,z1,z1_n1,z1_lb1,z2,z2_n1,z2_lb1,y,y_n1,y_lb1,tau,x,x_n1,x_lb1,y2,y2_n1,y2_lb1,finished)

  ! TODO Copy results back to host
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  CALL hipCheck(hipMemcpy(c_loc(???),???,C_SIZEOF(???),hipMemcpyDeviceToHost)
  ! ... might be more (or less) than two memcopies 
  ! TODO Compare results
  ! TODO Update error code if the results do not match
  return errorCode
end function


program test_zhetrd_gpu_kernels
  implicit none
  integer :: globalErrorCode = 0, errorCode, fails = 0, tests = 0
  ! declare test functions and return type
  integer :: test_launch_krnl_2b8e8f_0_auto
  integer :: test_launch_krnl_9c27cb_1_auto
  integer :: test_launch_zher2_mv_kernel
  integer :: test_launch_zlarfg_kernel
  integer :: test_launch_zher2_mv_zlarfg_kernel
  integer :: test_launch_stacked_zgemv_c
  integer :: test_launch_stacked_zgemv_n
  integer :: test_launch_finish_w_col_kernel
  integer :: test_launch_stacked_zgemv_n_finish_w
  write(*,*) "SUITE test_zhetrd_gpu_kernels run ..."
  errorCode = test_launch_krnl_2b8e8f_0_auto()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_krnl_2b8e8f_0_auto ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_krnl_2b8e8f_0_auto ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_krnl_9c27cb_1_auto()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_krnl_9c27cb_1_auto ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_krnl_9c27cb_1_auto ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_zher2_mv_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_zher2_mv_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_zher2_mv_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_zlarfg_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_zlarfg_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_zlarfg_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_zher2_mv_zlarfg_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_zher2_mv_zlarfg_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_zher2_mv_zlarfg_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_zgemv_c()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_zgemv_c ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_zgemv_c ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_zgemv_n()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_zgemv_n ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_zgemv_n ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_finish_w_col_kernel()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_finish_w_col_kernel ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_finish_w_col_kernel ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode
  errorCode = test_launch_stacked_zgemv_n_finish_w()
  IF (errorCode > 0) THEN
    fails = fails + 1
    write(*,*) "TEST test_launch_stacked_zgemv_n_finish_w ... FAILURE"
  ELSE 
    write(*,*) "TEST test_launch_stacked_zgemv_n_finish_w ... SUCCESS"
  END IF
  tests = tests + 1
  globalErrorCode = globalErrorCode + errorCode

  IF (globalErrorCode > 0) THEN
    write(*,*) "SUITE test_zhetrd_gpu_kernels ... FAILURE passed:",(tests-fails)," failed:",fails," total:",tests
  ELSE 
    write(*,*) "SUITE test_zhetrd_gpu_kernels ... SUCCESS passed:",(tests-fails)," failed:",fails," total:",tests
  END IF
end program test_zhetrd_gpu_kernels